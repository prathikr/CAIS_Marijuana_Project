{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'city_name', 'offense_code', 'offense_type', 'offense_group',\n",
       "       'offense_against', 'date_single', 'longitude', 'latitude',\n",
       "       'location_type', 'location_category', 'census_block', 'date_start',\n",
       "       'date_end'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import csv\n",
    "\n",
    "databases = ['crime_open_database_core_2018.csv', 'crime_open_database_core_2017.csv']\n",
    "\n",
    "crimes_df = pd.DataFrame()\n",
    "\n",
    "for db in databases:\n",
    "    temp = pd.read_csv(\"national_crime_data/\" + db)\n",
    "    crimes_df = pd.concat([crimes_df, temp], ignore_index=True)\n",
    "    #print(db + \" -> \" + str(len(crimes_df)))\n",
    "    \n",
    "crimes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Credit for this code goes to Sarah Okamoto, modified by Prathik Rao\n",
    "######################################################################\n",
    "\n",
    "# downloaded Virginia dataframe from tiger:\n",
    "# https://www2.census.gov/geo/tiger/TIGER2019/TRACT/\n",
    "\n",
    "# https://www2.census.gov/geo/tiger/TIGER2019/TRACT/tl_2019_01_tract.zip\n",
    "\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# create new dataframe with fips_code_col column\n",
    "# start with empty column\n",
    "# final_df = raw_df.assign(fips_code_col = [])\n",
    "\n",
    "# create empty dictionary mapping (lat, lon) to fips code\n",
    "state_lookup = {}\n",
    "\n",
    "bad_lat_lons = set()\n",
    "# loop through all rows in csv\n",
    "\n",
    "# stores corresponding fips codes in a list so that we can just add them as a new column afterwards\n",
    "state_codes = []\n",
    "for ind, row in crimes_df.iterrows():\n",
    "    # From dataset, get lat lon from columns for each row\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    lookup_key = f\"({lat}, {lon})\"\n",
    "    # Check if (lat, lon) is in dictionary\n",
    "    if lookup_key in state_lookup:\n",
    "        # use that stored value if so\n",
    "        state_code = state_lookup[lookup_key]\n",
    "    else:\n",
    "        # call API to get FIPS code from lat, lon\n",
    "        # note: point may be using lon, lat instead of lat, lon\n",
    "        point_request = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat}&longitude={lon}&showall=false&format=json\"\n",
    "        with urllib.request.urlopen(point_request) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "        # get everything except last 4 items from fips block code\n",
    "        if data[\"State\"][\"code\"] is None:\n",
    "            print(f\"something went wrong with ({lat}, {lon})\")\n",
    "            state_code = None\n",
    "            bad_lat_lons.add((lat, lon, row[\"agyaddr\"]))\n",
    "        else:\n",
    "            state_code = data[\"State\"][\"code\"]\n",
    "        state_lookup[lookup_key] = state_code\n",
    "    # append state_code to end of csv\n",
    "    state_codes.append(state_code)\n",
    "\n",
    "\n",
    "print(\"bad lat lons:\")\n",
    "print(bad_lat_lons)\n",
    "bad_lat_lon_df = pd.DataFrame(bad_lat_lons, columns=[\"latitude\", \"longitude\"])\n",
    "bad_lat_lon_df.to_csv(\"bad_lat_lons.csv\")\n",
    "\n",
    "# stores state codes in raw dataframe\n",
    "crimes_df['state_code'] = state_code\n",
    "\n",
    "# drop rows that aren't filled with a state value\n",
    "# crimes_df = crimes_df.dropna(subset=['state_code'])\n",
    "\n",
    "crimes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = crimes_df[['city_name','offense_against']]\n",
    "criminal_offenses = temp[temp.offense_against == \"persons\"]\n",
    "civil_offenses = temp[temp.offense_against == \"property\"]\n",
    "other_offenses = temp[temp.offense_against.isin([\"society\", \"other\"])]\n",
    "other_offenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criminal_offenses_count_by_city = criminal_offenses.groupby('city_name').count()\n",
    "criminal_offenses_count_by_city.rename(columns = {'offense_against':'city_level_criminal_offense_count'}, inplace = True) \n",
    "civil_offenses_count_by_city = civil_offenses.groupby('city_name').count()\n",
    "civil_offenses_count_by_city.rename(columns = {'offense_against':'city_level_civil_offense_count'}, inplace = True) \n",
    "other_offenses_count_by_city = other_offenses.groupby('city_name').count()\n",
    "other_offenses_count_by_city.rename(columns = {'offense_against':'city_level_other_offense_count'}, inplace = True) \n",
    "\n",
    "\n",
    "crime_stats = pd.merge(criminal_offenses_count_by_city, civil_offenses_count_by_city, on='city_name')\n",
    "crime_stats = pd.merge(crime_stats, other_offenses_count_by_city, on='city_name')\n",
    "crime_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BISTRA_GROUP_PROJECT_SMALL.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.City.unique())\n",
    "print(crime_stats.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, crime_stats, left_on='City', right_on='city_name')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for displaying table data\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display_html\n",
    "\n",
    "# n is the number of columns to display data in\n",
    "def display_side_by_side(series_obj, n):\n",
    "    df = pd.DataFrame(series_obj)\n",
    "    partition = int(round(len(df) / n))\n",
    "    lower_bound = 0\n",
    "    upper_bound = partition\n",
    "    args = []\n",
    "    for i in range(n):\n",
    "        args.append(df[lower_bound:upper_bound])\n",
    "        lower_bound += partition\n",
    "        upper_bound += partition\n",
    "    helper(args)\n",
    "\n",
    "def helper(args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    \n",
    "# replace all -999 with NaN inplace\n",
    "merged.replace(to_replace = -999, value = np.nan, inplace=True)\n",
    "\n",
    "# calculate percentage of NaNs in each column\n",
    "percent_missing = merged.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': merged.columns,'percent_missing': percent_missing})\n",
    "\n",
    "display_side_by_side(missing_value_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['City']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
