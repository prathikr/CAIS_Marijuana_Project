{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read original data file from Jordan\n",
    "raw_df = pd.read_csv(\"crime_open_database_sample_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate address but remove all extra delimeters\n",
    "requests = raw_df.apply(lambda row: (row[\"city_name\"]).replace(\",\",\"\"), axis=1)\n",
    "#requests = raw_df.apply(lambda row: (row[\"agyaddr\"]+\" \"+row[\"City\"]+\" \"+row[\"State\"] + \" \"+row[\"zipcode\"]).replace(\",\",\"\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ucla requests and then paste into geocoder api\n",
    "# then paste into a new results file\n",
    "# https://gis.ucla.edu/geocoder\n",
    "\n",
    "pd.DataFrame(set(requests)).astype(str).to_csv(\"ucla_requests.csv\", header=False, index=False, quoting=csv.QUOTE_NONE, escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lat lon results from UCLA Geocode API\n",
    "df1 = pd.read_csv(\"ucla_result.csv\")\n",
    "\n",
    "# remove extra characters and join lat lons to original data file\n",
    "df1[\"ADDRESS\"] = df1[\"ADDRESS\"].str.replace(\"'\",\"\").str.replace(\" \",\"\")\n",
    "df1 = df1.set_index(\"ADDRESS\")\n",
    "\n",
    "# create a dictionary that maps addresses to lat or lon\n",
    "lat_lon_lookup = df1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-4749fca08246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get all lat lons and add the columns to original data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat_lon_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat_lon_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'latitude'"
     ]
    }
   ],
   "source": [
    "lats = []\n",
    "lons = []\n",
    "\n",
    "# get all lat lons and add the columns to original data file\n",
    "for row in requests:\n",
    "    lat = lat_lon_lookup[\"latitude\"][row.replace(\" \", \"\")]\n",
    "    lon = lat_lon_lookup[\"longitude\"][row.replace(\" \", \"\")]\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "raw_df[\"latitude\"] = lats\n",
    "raw_df[\"longitude\"] = lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# create empty dictionary mapping (lat, lon) to fips code\n",
    "fips_lookup = {}\n",
    "\n",
    "bad_lat_lons = set()\n",
    "# loop through all rows in csv\n",
    "\n",
    "# stores corresponding fips codes in a list so that we can just add them as a new column afterwards\n",
    "fips_codes = []\n",
    "for ind, row in raw_df.iterrows():\n",
    "    # From dataset, get lat lon from columns for each row\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    lookup_key = f\"({lat}, {lon})\"\n",
    "    # Check if (lat, lon) is in dictionary\n",
    "    if lookup_key in fips_lookup:\n",
    "        # use that stored value if so\n",
    "        fips_code = fips_lookup[lookup_key]\n",
    "    else:\n",
    "        # call API to get FIPS code from lat, lon\n",
    "        # note: point may be using lon, lat instead of lat, lon\n",
    "        point_request = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat}&longitude={lon}&showall=false&format=json\"\n",
    "        with urllib.request.urlopen(point_request) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "        # get everything except last 4 items from fips block code\n",
    "        if data[\"Block\"][\"FIPS\"] is None:\n",
    "            print(f\"something went wrong with ({lat}, {lon})\")\n",
    "            fips_code = None\n",
    "            bad_lat_lons.add((lat, lon, row[\"agyaddr\"]))\n",
    "        else:\n",
    "            fips_code = data[\"Block\"][\"FIPS\"][:-4]\n",
    "        fips_lookup[lookup_key] = fips_code\n",
    "    # append fips_code to end of csv\n",
    "    fips_codes.append(fips_code)\n",
    "\n",
    "\n",
    "print(\"bad lat lons:\")\n",
    "print(bad_lat_lons)\n",
    "bad_lat_lon_df = pd.DataFrame(bad_lat_lons, columns=[\"latitude\", \"longitude\", \"agyaddr\"])\n",
    "bad_lat_lon_df.to_csv(\"bad_lat_lons.csv\")\n",
    "\n",
    "# store FIPS codes in raw dataframe\n",
    "raw_df['FIPS_code'] = fips_codes\n",
    "\n",
    "# drop row because there are only 130 /14000 rows, negligible\n",
    "raw_df = raw_df.dropna(subset=['FIPS_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
