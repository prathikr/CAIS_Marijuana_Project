{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Credit for this code goes to Sarah Okamoto, modified by Prathik Rao\n",
    "######################################################################\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import csv\n",
    "\n",
    "# read original data file from Jordan\n",
    "raw_df = pd.read_csv(\"BISTRA_GROUP_PROJECT_SMALL.csv\")\n",
    "\n",
    "# concatenate address but remove all extra delimeters\n",
    "requests = raw_df.apply(lambda row: (row[\"agyaddr\"]+\" \"+row[\"City\"]+\" \"+row[\"State\"] + \" \"+row[\"zipcode\"]).replace(\",\",\"\"), axis=1)\n",
    "\n",
    "# open ucla requests and then paste into geocoder api\n",
    "# then paste into a new results file\n",
    "# https://gis.ucla.edu/geocoder\n",
    "\n",
    "pd.DataFrame(set(requests)).astype(str).to_csv(\"ucla_requests.csv\", header=False, index=False, quoting=csv.QUOTE_NONE, escapechar=\" \")\n",
    "\n",
    "# read lat lon results from UCLA Geocode API\n",
    "df1 = pd.read_csv(\"ucla_result.csv\")\n",
    "\n",
    "# remove extra characters and join lat lons to original data file\n",
    "df1[\"ADDRESS\"] = df1[\"ADDRESS\"].str.replace(\"'\",\"\").str.replace(\" \",\"\")\n",
    "df1 = df1.set_index(\"ADDRESS\")\n",
    "\n",
    "# create a dictionary that maps addresses to lat or lon\n",
    "lat_lon_lookup = df1.to_dict()\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "# get all lat lons and add the columns to original data file\n",
    "for row in requests:\n",
    "    lat = lat_lon_lookup[\"LATITUDE\"][row.replace(\" \", \"\")]\n",
    "    lon = lat_lon_lookup[\"LONGITUDE\"][row.replace(\" \", \"\")]\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "raw_df[\"latitude\"] = lats\n",
    "raw_df[\"longitude\"] = lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong with (34.262834000000005, -119.848555)\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Credit for this code goes to Sarah Okamoto, modified by Prathik Rao\n",
    "######################################################################\n",
    "\n",
    "# downloaded Virginia dataframe from tiger:\n",
    "# https://www2.census.gov/geo/tiger/TIGER2019/TRACT/\n",
    "\n",
    "# https://www2.census.gov/geo/tiger/TIGER2019/TRACT/tl_2019_01_tract.zip\n",
    "\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# create new dataframe with fips_code_col column\n",
    "# start with empty column\n",
    "# final_df = raw_df.assign(fips_code_col = [])\n",
    "\n",
    "# create empty dictionary mapping (lat, lon) to fips code\n",
    "fips_lookup = {}\n",
    "\n",
    "bad_lat_lons = set()\n",
    "# loop through all rows in csv\n",
    "\n",
    "# stores corresponding fips codes in a list so that we can just add them as a new column afterwards\n",
    "fips_codes = []\n",
    "for ind, row in raw_df.iterrows():\n",
    "    # From dataset, get lat lon from columns for each row\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    lookup_key = f\"({lat}, {lon})\"\n",
    "    # Check if (lat, lon) is in dictionary\n",
    "    if lookup_key in fips_lookup:\n",
    "        # use that stored value if so\n",
    "        fips_code = fips_lookup[lookup_key]\n",
    "    else:\n",
    "        # call API to get FIPS code from lat, lon\n",
    "        # note: point may be using lon, lat instead of lat, lon\n",
    "        point_request = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat}&longitude={lon}&showall=false&format=json\"\n",
    "        with urllib.request.urlopen(point_request) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "        # get everything except last 4 items from fips block code\n",
    "        if data[\"County\"][\"FIPS\"] is None:\n",
    "            print(f\"something went wrong with ({lat}, {lon})\")\n",
    "            fips_code = None\n",
    "            bad_lat_lons.add((lat, lon, row[\"agyaddr\"]))\n",
    "        else:\n",
    "            fips_code = data[\"County\"][\"FIPS\"]\n",
    "        fips_lookup[lookup_key] = fips_code\n",
    "    # append fips_code to end of csv\n",
    "    fips_codes.append(fips_code)\n",
    "\n",
    "\n",
    "print(\"bad lat lons:\")\n",
    "print(bad_lat_lons)\n",
    "bad_lat_lon_df = pd.DataFrame(bad_lat_lons, columns=[\"latitude\", \"longitude\", \"agyaddr\"])\n",
    "bad_lat_lon_df.to_csv(\"bad_lat_lons.csv\")\n",
    "\n",
    "# store FIPS codes in raw dataframe\n",
    "raw_df['FIPS_code'] = fips_codes\n",
    "\n",
    "# drop row because there are only 130 /14000 rows, negligible\n",
    "raw_df = raw_df.dropna(subset=['FIPS_code'])\n",
    "\n",
    "# save dataframe to csv\n",
    "raw_df.to_csv(\"BISTRA_GROUP_PROJECT_SMALL_with_lat_lon_and_fips.csv\")\n",
    "\n",
    "# dump fips lookup table to json file in case we need it later\n",
    "with open(\"fips_lookup.json\", \"w\") as f:\n",
    "    json.dump(fips_lookup, f)\n",
    "    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: join 2018 national crime rates with database via FIPS code\n",
    "# Step 1: add FIPS code to crimes database\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "crimes_df = pd.read_csv(\"crime_open_database_core_2018.csv\")\n",
    "crimes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = crimes_df[['city_name','offense_against']]\n",
    "criminal_offenses = temp[temp.offense_against == \"persons\"]\n",
    "criminal_offenses.offense_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_by_city = criminal_offenses.groupby('city_name').count() / len(criminal_offenses)\n",
    "percentage_by_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_lookup = {}\n",
    "\n",
    "bad_lat_lons = set()\n",
    "# loop through all rows in csv\n",
    "\n",
    "# stores corresponding fips codes in a list so that we can just add them as a new column afterwards\n",
    "fips_codes = []\n",
    "for ind, row in crimes_df.iterrows():\n",
    "    # From dataset, get lat lon from columns for each row\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    lookup_key = f\"({lat}, {lon})\"\n",
    "    # Check if (lat, lon) is in dictionary\n",
    "    if lookup_key in fips_lookup:\n",
    "        # use that stored value if so\n",
    "        fips_code = fips_lookup[lookup_key]\n",
    "    else:\n",
    "        # call API to get FIPS code from lat, lon\n",
    "        # note: point may be using lon, lat instead of lat, lon\n",
    "        point_request = f\"https://geo.fcc.gov/api/census/block/find?latitude={lat}&longitude={lon}&showall=false&format=json\"\n",
    "        with urllib.request.urlopen(point_request) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "        # get everything except last 4 items from fips block code\n",
    "        if data[\"County\"][\"FIPS\"] is None:\n",
    "            print(f\"something went wrong with ({lat}, {lon})\")\n",
    "            fips_code = None\n",
    "            bad_lat_lons.add((lat, lon, row[\"agyaddr\"]))\n",
    "        else:\n",
    "            fips_code = data[\"County\"][\"FIPS\"]\n",
    "        fips_lookup[lookup_key] = fips_code\n",
    "    # append fips_code to end of csv\n",
    "    fips_codes.append(fips_code)\n",
    "\n",
    "\n",
    "print(\"bad lat lons:\")\n",
    "print(bad_lat_lons)\n",
    "bad_lat_lon_df = pd.DataFrame(bad_lat_lons, columns=[\"latitude\", \"longitude\", \"agyaddr\"])\n",
    "bad_lat_lon_df.to_csv(\"bad_lat_lons.csv\")\n",
    "\n",
    "# store FIPS codes in raw dataframe\n",
    "crimes_df['FIPS_code'] = fips_codes\n",
    "\n",
    "# drop row because there are only 130 /14000 rows, negligible\n",
    "crimes_df = crimes_df.dropna(subset=['FIPS_code'])\n",
    "\n",
    "# save dataframe to csv\n",
    "#crimes_df.to_csv(\"crime_open_database_core_2018_with_fips.csv\")\n",
    "\n",
    "# dump fips lookup table to json file in case we need it later\n",
    "with open(\"fips_lookup.json\", \"w\") as f:\n",
    "    json.dump(fips_lookup, f)\n",
    "    \n",
    "crimes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
